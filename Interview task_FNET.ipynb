{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "irish-gasoline",
   "metadata": {},
   "source": [
    "# Interview task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "auburn-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 20\n",
    "MODEL_NAME = \"google/fnet-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-practice",
   "metadata": {},
   "source": [
    "## check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "unlikely-easter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-detroit",
   "metadata": {},
   "source": [
    "## Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "reported-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sharing-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('substance_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "endless-washington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_START_INDEX</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1329</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1541</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>741</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_START_INDEX  OBJECT_END_INDEX  OBJECT_SCORE OBJECT_DIST  \\\n",
       "0                1329              1332          1000           2   \n",
       "1                 912               919           888           1   \n",
       "2                1541              1550          1000           1   \n",
       "3                 741               745           694           0   \n",
       "4                 480               491          1000           3   \n",
       "\n",
       "   OBJECT_MAXDIST     OBJECT_CUI OBJECT_NOVELTY  TYPE  \\\n",
       "0               2       C0004057              1    ab   \n",
       "1              15       C0242417              1    ab   \n",
       "2               1       C0003805              1    ab   \n",
       "3               4  C0169658|3716              1    ab   \n",
       "4               5       C0039815              1    ab   \n",
       "\n",
       "                                            SENTENCE  LABEL  \n",
       "0  Nor did administration of SA, diflunisal or AS...      n  \n",
       "1  A       comparative study of recombinant L-cha...      n  \n",
       "2  These findings suggest that some nicotinic alk...      y  \n",
       "3  With a       truncated chimaeric IL-5Rbeta-gp1...      y  \n",
       "4  Neutral       endopeptidase, a zinc-dependent ...      n  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "assured-hungary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "established-maryland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>triple_with_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_END_INDEX  OBJECT_SCORE  OBJECT_DIST OBJECT_MAXDIST     OBJECT_CUI  \\\n",
       "0              1332          1000            2              2       C0004057   \n",
       "1               919           888            1             15       C0242417   \n",
       "2              1550          1000            1              1       C0003805   \n",
       "3               745           694            0              4  C0169658|3716   \n",
       "4               491          1000            3              5       C0039815   \n",
       "\n",
       "  OBJECT_NOVELTY TYPE                                           SENTENCE  \\\n",
       "0              1   ab  Nor did administration of SA, diflunisal or AS...   \n",
       "1              1   ab  A       comparative study of recombinant L-cha...   \n",
       "2              1   ab  These findings suggest that some nicotinic alk...   \n",
       "3              1   ab  With a       truncated chimaeric IL-5Rbeta-gp1...   \n",
       "4              1   ab  Neutral       endopeptidase, a zinc-dependent ...   \n",
       "\n",
       "   LABEL                               triple_with_sentence  \n",
       "0      n  Nor did administration of SA, diflunisal or AS...  \n",
       "1      n  A       comparative study of recombinant L-cha...  \n",
       "2      y  These findings suggest that some nicotinic alk...  \n",
       "3      y  With a       truncated chimaeric IL-5Rbeta-gp1...  \n",
       "4      n  Neutral       endopeptidase, a zinc-dependent ...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(example):\n",
    "    sentence = example['SENTENCE']\n",
    "    subject = example['SUBJECT_TEXT']\n",
    "    object = example['OBJECT_TEXT']\n",
    "    relation = example['PREDICATE']\n",
    "    # text = f\"{subject} [SEP] {relation} [SEP] {object} [SEP] {sentence}\"\n",
    "    text = f\"{sentence} [SEP] {subject} , {relation} , {object}\"\n",
    "    return text\n",
    "\n",
    "df['triple_with_sentence'] = df.apply(pre_processing,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-terminology",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "convertible-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-saturn",
   "metadata": {},
   "source": [
    "#### test tokenizer for a triple with corresponding sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "least-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nor did administration of SA, diflunisal or ASA itself impair the       anti-aggregatory effect of a fresh test dose of ASA. [SEP] SA , INTERACTS_WITH , ASA'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['triple_with_sentence'].iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "limited-basic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    4,  5014,   707,  5295,    39,  8410, 16680,   511, 16667,   112,\n",
       "         16036,   118,  4835, 16685,  2630,   366,   635,    13,  4293, 16688,\n",
       "         13324,  2506,  2462,   992,    39,     8,  2604,  1123,  9466,    39,\n",
       "          4835, 16685, 16678, 16657,     5,  8410,  1829,  3251,  7906,  2381,\n",
       "          4597, 16742, 16694, 10205,  1829,  4835, 16685,     5]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example, return_tensors='pt', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "defined-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(example):\n",
    "    res = tokenizer(example['triple_with_sentence'])\n",
    "    # res['label'] = example['LABEL']\n",
    "    res['label'] = 1 if example['LABEL']=='y' else 0\n",
    "    return res\n",
    "df['data'] = df.apply(processing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "occupational-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4, 5014, 707, 5295, 39, 8410, 16680, 511, 16667, 112, 16036, 118, 4835, 16685, 2630, 366, 635, 13, 4293, 16688, 13324, 2506, 2462, 992, 39, 8, 2604, 1123, 9466, 39, 4835, 16685, 16678, 16657, 5, 8410, 1829, 3251, 7906, 2381, 4597, 16742, 16694, 10205, 1829, 4835, 16685, 5], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "brazilian-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL', 'triple_with_sentence', 'data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-direction",
   "metadata": {},
   "source": [
    "## split the data, training set 70%, validation set 15%, test set 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "reverse-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=RANDOM_STATE)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cubic-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 450 450\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(val_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "modern-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index()\n",
    "val_data = val_data.reset_index()\n",
    "test_data = test_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "hearing-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# import evaluate\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "prime-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\t    predictions, labels = eval_pred\n",
    "\t    predictions = np.argmax(predictions, axis=1)\n",
    "\t    \n",
    "\t    # Calculate precision, recall, and F1 score\n",
    "\t    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "\t    \n",
    "\t    return {\n",
    "\t        'accuracy': accuracy_score(labels, predictions),\n",
    "\t        'precision': precision,\n",
    "\t        'recall': recall,\n",
    "\t        'f1': f1\n",
    "\t    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-sunset",
   "metadata": {},
   "source": [
    "## BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "loved-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type fnet to instantiate a model of type ctrl. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'n', 1: 'y'}\n",
      "label2id: {'n': 0, 'y': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CTRLForSequenceClassification were not initialized from the model checkpoint at google/fnet-base and are newly initialized: ['classifier.weight', 'h.0.ffn.0.bias', 'h.0.ffn.0.weight', 'h.0.ffn.2.bias', 'h.0.ffn.2.weight', 'h.0.layernorm1.bias', 'h.0.layernorm1.weight', 'h.0.layernorm2.bias', 'h.0.layernorm2.weight', 'h.0.multi_head_attention.Wk.bias', 'h.0.multi_head_attention.Wk.weight', 'h.0.multi_head_attention.Wq.bias', 'h.0.multi_head_attention.Wq.weight', 'h.0.multi_head_attention.Wv.bias', 'h.0.multi_head_attention.Wv.weight', 'h.0.multi_head_attention.dense.bias', 'h.0.multi_head_attention.dense.weight', 'h.1.ffn.0.bias', 'h.1.ffn.0.weight', 'h.1.ffn.2.bias', 'h.1.ffn.2.weight', 'h.1.layernorm1.bias', 'h.1.layernorm1.weight', 'h.1.layernorm2.bias', 'h.1.layernorm2.weight', 'h.1.multi_head_attention.Wk.bias', 'h.1.multi_head_attention.Wk.weight', 'h.1.multi_head_attention.Wq.bias', 'h.1.multi_head_attention.Wq.weight', 'h.1.multi_head_attention.Wv.bias', 'h.1.multi_head_attention.Wv.weight', 'h.1.multi_head_attention.dense.bias', 'h.1.multi_head_attention.dense.weight', 'h.10.ffn.0.bias', 'h.10.ffn.0.weight', 'h.10.ffn.2.bias', 'h.10.ffn.2.weight', 'h.10.layernorm1.bias', 'h.10.layernorm1.weight', 'h.10.layernorm2.bias', 'h.10.layernorm2.weight', 'h.10.multi_head_attention.Wk.bias', 'h.10.multi_head_attention.Wk.weight', 'h.10.multi_head_attention.Wq.bias', 'h.10.multi_head_attention.Wq.weight', 'h.10.multi_head_attention.Wv.bias', 'h.10.multi_head_attention.Wv.weight', 'h.10.multi_head_attention.dense.bias', 'h.10.multi_head_attention.dense.weight', 'h.11.ffn.0.bias', 'h.11.ffn.0.weight', 'h.11.ffn.2.bias', 'h.11.ffn.2.weight', 'h.11.layernorm1.bias', 'h.11.layernorm1.weight', 'h.11.layernorm2.bias', 'h.11.layernorm2.weight', 'h.11.multi_head_attention.Wk.bias', 'h.11.multi_head_attention.Wk.weight', 'h.11.multi_head_attention.Wq.bias', 'h.11.multi_head_attention.Wq.weight', 'h.11.multi_head_attention.Wv.bias', 'h.11.multi_head_attention.Wv.weight', 'h.11.multi_head_attention.dense.bias', 'h.11.multi_head_attention.dense.weight', 'h.2.ffn.0.bias', 'h.2.ffn.0.weight', 'h.2.ffn.2.bias', 'h.2.ffn.2.weight', 'h.2.layernorm1.bias', 'h.2.layernorm1.weight', 'h.2.layernorm2.bias', 'h.2.layernorm2.weight', 'h.2.multi_head_attention.Wk.bias', 'h.2.multi_head_attention.Wk.weight', 'h.2.multi_head_attention.Wq.bias', 'h.2.multi_head_attention.Wq.weight', 'h.2.multi_head_attention.Wv.bias', 'h.2.multi_head_attention.Wv.weight', 'h.2.multi_head_attention.dense.bias', 'h.2.multi_head_attention.dense.weight', 'h.3.ffn.0.bias', 'h.3.ffn.0.weight', 'h.3.ffn.2.bias', 'h.3.ffn.2.weight', 'h.3.layernorm1.bias', 'h.3.layernorm1.weight', 'h.3.layernorm2.bias', 'h.3.layernorm2.weight', 'h.3.multi_head_attention.Wk.bias', 'h.3.multi_head_attention.Wk.weight', 'h.3.multi_head_attention.Wq.bias', 'h.3.multi_head_attention.Wq.weight', 'h.3.multi_head_attention.Wv.bias', 'h.3.multi_head_attention.Wv.weight', 'h.3.multi_head_attention.dense.bias', 'h.3.multi_head_attention.dense.weight', 'h.4.ffn.0.bias', 'h.4.ffn.0.weight', 'h.4.ffn.2.bias', 'h.4.ffn.2.weight', 'h.4.layernorm1.bias', 'h.4.layernorm1.weight', 'h.4.layernorm2.bias', 'h.4.layernorm2.weight', 'h.4.multi_head_attention.Wk.bias', 'h.4.multi_head_attention.Wk.weight', 'h.4.multi_head_attention.Wq.bias', 'h.4.multi_head_attention.Wq.weight', 'h.4.multi_head_attention.Wv.bias', 'h.4.multi_head_attention.Wv.weight', 'h.4.multi_head_attention.dense.bias', 'h.4.multi_head_attention.dense.weight', 'h.5.ffn.0.bias', 'h.5.ffn.0.weight', 'h.5.ffn.2.bias', 'h.5.ffn.2.weight', 'h.5.layernorm1.bias', 'h.5.layernorm1.weight', 'h.5.layernorm2.bias', 'h.5.layernorm2.weight', 'h.5.multi_head_attention.Wk.bias', 'h.5.multi_head_attention.Wk.weight', 'h.5.multi_head_attention.Wq.bias', 'h.5.multi_head_attention.Wq.weight', 'h.5.multi_head_attention.Wv.bias', 'h.5.multi_head_attention.Wv.weight', 'h.5.multi_head_attention.dense.bias', 'h.5.multi_head_attention.dense.weight', 'h.6.ffn.0.bias', 'h.6.ffn.0.weight', 'h.6.ffn.2.bias', 'h.6.ffn.2.weight', 'h.6.layernorm1.bias', 'h.6.layernorm1.weight', 'h.6.layernorm2.bias', 'h.6.layernorm2.weight', 'h.6.multi_head_attention.Wk.bias', 'h.6.multi_head_attention.Wk.weight', 'h.6.multi_head_attention.Wq.bias', 'h.6.multi_head_attention.Wq.weight', 'h.6.multi_head_attention.Wv.bias', 'h.6.multi_head_attention.Wv.weight', 'h.6.multi_head_attention.dense.bias', 'h.6.multi_head_attention.dense.weight', 'h.7.ffn.0.bias', 'h.7.ffn.0.weight', 'h.7.ffn.2.bias', 'h.7.ffn.2.weight', 'h.7.layernorm1.bias', 'h.7.layernorm1.weight', 'h.7.layernorm2.bias', 'h.7.layernorm2.weight', 'h.7.multi_head_attention.Wk.bias', 'h.7.multi_head_attention.Wk.weight', 'h.7.multi_head_attention.Wq.bias', 'h.7.multi_head_attention.Wq.weight', 'h.7.multi_head_attention.Wv.bias', 'h.7.multi_head_attention.Wv.weight', 'h.7.multi_head_attention.dense.bias', 'h.7.multi_head_attention.dense.weight', 'h.8.ffn.0.bias', 'h.8.ffn.0.weight', 'h.8.ffn.2.bias', 'h.8.ffn.2.weight', 'h.8.layernorm1.bias', 'h.8.layernorm1.weight', 'h.8.layernorm2.bias', 'h.8.layernorm2.weight', 'h.8.multi_head_attention.Wk.bias', 'h.8.multi_head_attention.Wk.weight', 'h.8.multi_head_attention.Wq.bias', 'h.8.multi_head_attention.Wq.weight', 'h.8.multi_head_attention.Wv.bias', 'h.8.multi_head_attention.Wv.weight', 'h.8.multi_head_attention.dense.bias', 'h.8.multi_head_attention.dense.weight', 'h.9.ffn.0.bias', 'h.9.ffn.0.weight', 'h.9.ffn.2.bias', 'h.9.ffn.2.weight', 'h.9.layernorm1.bias', 'h.9.layernorm1.weight', 'h.9.layernorm2.bias', 'h.9.layernorm2.weight', 'h.9.multi_head_attention.Wk.bias', 'h.9.multi_head_attention.Wk.weight', 'h.9.multi_head_attention.Wq.bias', 'h.9.multi_head_attention.Wq.weight', 'h.9.multi_head_attention.Wv.bias', 'h.9.multi_head_attention.Wv.weight', 'h.9.multi_head_attention.dense.bias', 'h.9.multi_head_attention.dense.weight', 'layernorm.bias', 'layernorm.weight', 'w.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import CTRLForSequenceClassification\n",
    "\n",
    "labels = ['n', 'y']\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "\n",
    "print('id2label:', id2label)\n",
    "print('label2id:', label2id)\n",
    "\n",
    "model = CTRLForSequenceClassification.from_pretrained(MODEL_NAME, ignore_mismatched_sizes=True, num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Only train last classifier layer\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# resize model embedding to match new tokenizer\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # fix model padding token id\n",
    "# model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "chicken-feature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTRLForSequenceClassification(\n",
       "  (transformer): CTRLModel(\n",
       "    (w): Embedding(32000, 768)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x EncoderLayer(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=8192, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8192, out_features=768, bias=True)\n",
       "        )\n",
       "        (layernorm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "simplified-volume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last one\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# for param in model.bert.pooler.dense.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # Unfreeze the last three layers\n",
    "# for param in model.transformer.ln_f.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "clear-empire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204066816"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "constitutional-roller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-sellers",
   "metadata": {},
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aware-roman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='my_best_model',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "limiting-stephen",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci5541/zhan8023/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [660/660 02:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.699047</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.664567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692125</td>\n",
       "      <td>0.537778</td>\n",
       "      <td>0.542105</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.664516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688142</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.548813</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.672052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685332</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.673171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684374</td>\n",
       "      <td>0.568889</td>\n",
       "      <td>0.559585</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.690096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682283</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.679612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.556430</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.682770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.680211</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.558904</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.674380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.679775</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.556474</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.669983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.679681</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555249</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.667774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=660, training_loss=0.6932404836018881, metrics={'train_runtime': 133.4602, 'train_samples_per_second': 157.35, 'train_steps_per_second': 4.945, 'total_flos': 3456234946953216.0, 'train_loss': 0.6932404836018881, 'epoch': 10.0})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data['data'],\n",
    "    eval_dataset=val_data['data'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dimensional-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6725935935974121,\n",
       " 'eval_accuracy': 0.5704761904761905,\n",
       " 'eval_precision': 0.5694444444444444,\n",
       " 'eval_recall': 0.8330388692579506,\n",
       " 'eval_f1': 0.6764705882352942,\n",
       " 'eval_runtime': 9.1875,\n",
       " 'eval_samples_per_second': 228.571,\n",
       " 'eval_steps_per_second': 7.184,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "upset-prefix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6796807050704956,\n",
       " 'eval_accuracy': 0.5555555555555556,\n",
       " 'eval_precision': 0.5552486187845304,\n",
       " 'eval_recall': 0.8375,\n",
       " 'eval_f1': 0.6677740863787376,\n",
       " 'eval_runtime': 1.8437,\n",
       " 'eval_samples_per_second': 244.078,\n",
       " 'eval_steps_per_second': 8.136,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(val_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dramatic-pointer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6817827820777893,\n",
       " 'eval_accuracy': 0.5311111111111111,\n",
       " 'eval_precision': 0.5307262569832403,\n",
       " 'eval_recall': 0.8154506437768241,\n",
       " 'eval_f1': 0.6429780033840947,\n",
       " 'eval_runtime': 1.7213,\n",
       " 'eval_samples_per_second': 261.423,\n",
       " 'eval_steps_per_second': 8.714,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-clone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "golden-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -r my_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-welcome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_jupyter_a40",
   "language": "python",
   "name": "pytorch_jupyter_a40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dirty-deviation",
   "metadata": {},
   "source": [
    "# Interview task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "awful-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-neo-1.3B\"\n",
    "RANDOM_STATE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-melbourne",
   "metadata": {},
   "source": [
    "## check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grave-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-petersburg",
   "metadata": {},
   "source": [
    "## Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "analyzed-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limited-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('substance_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varied-radar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_START_INDEX</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1329</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1541</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>741</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_START_INDEX  OBJECT_END_INDEX  OBJECT_SCORE OBJECT_DIST  \\\n",
       "0                1329              1332          1000           2   \n",
       "1                 912               919           888           1   \n",
       "2                1541              1550          1000           1   \n",
       "3                 741               745           694           0   \n",
       "4                 480               491          1000           3   \n",
       "\n",
       "   OBJECT_MAXDIST     OBJECT_CUI OBJECT_NOVELTY  TYPE  \\\n",
       "0               2       C0004057              1    ab   \n",
       "1              15       C0242417              1    ab   \n",
       "2               1       C0003805              1    ab   \n",
       "3               4  C0169658|3716              1    ab   \n",
       "4               5       C0039815              1    ab   \n",
       "\n",
       "                                            SENTENCE  LABEL  \n",
       "0  Nor did administration of SA, diflunisal or AS...      n  \n",
       "1  A       comparative study of recombinant L-cha...      n  \n",
       "2  These findings suggest that some nicotinic alk...      y  \n",
       "3  With a       truncated chimaeric IL-5Rbeta-gp1...      y  \n",
       "4  Neutral       endopeptidase, a zinc-dependent ...      n  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "drawn-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inside-theory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>triple_with_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_END_INDEX  OBJECT_SCORE  OBJECT_DIST OBJECT_MAXDIST     OBJECT_CUI  \\\n",
       "0              1332          1000            2              2       C0004057   \n",
       "1               919           888            1             15       C0242417   \n",
       "2              1550          1000            1              1       C0003805   \n",
       "3               745           694            0              4  C0169658|3716   \n",
       "4               491          1000            3              5       C0039815   \n",
       "\n",
       "  OBJECT_NOVELTY TYPE                                           SENTENCE  \\\n",
       "0              1   ab  Nor did administration of SA, diflunisal or AS...   \n",
       "1              1   ab  A       comparative study of recombinant L-cha...   \n",
       "2              1   ab  These findings suggest that some nicotinic alk...   \n",
       "3              1   ab  With a       truncated chimaeric IL-5Rbeta-gp1...   \n",
       "4              1   ab  Neutral       endopeptidase, a zinc-dependent ...   \n",
       "\n",
       "   LABEL                               triple_with_sentence  \n",
       "0      n  Nor did administration of SA, diflunisal or AS...  \n",
       "1      n  A       comparative study of recombinant L-cha...  \n",
       "2      y  These findings suggest that some nicotinic alk...  \n",
       "3      y  With a       truncated chimaeric IL-5Rbeta-gp1...  \n",
       "4      n  Neutral       endopeptidase, a zinc-dependent ...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(example):\n",
    "    sentence = example['SENTENCE']\n",
    "    subject = example['SUBJECT_TEXT']\n",
    "    object = example['OBJECT_TEXT']\n",
    "    relation = example['PREDICATE']\n",
    "    # text = f\"{subject} [SEP] {relation} [SEP] {object} [SEP] {sentence}\"\n",
    "    text = f\"{sentence} [SEP] {subject} , {relation} , {object}\"\n",
    "    return text\n",
    "\n",
    "df['triple_with_sentence'] = df.apply(pre_processing,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-cleanup",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "renewable-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci5541/zhan8023/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-bubble",
   "metadata": {},
   "source": [
    "#### test tokenizer for a triple with corresponding sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distributed-brisbane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nor did administration of SA, diflunisal or ASA itself impair the       anti-aggregatory effect of a fresh test dose of ASA. [SEP] SA , INTERACTS_WITH , ASA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['triple_with_sentence'].iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personalized-arctic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[21991,   750,  3662,   286, 14719,    11,   288,   361,    75,   403,\n",
       "         28456,   393, 49599,  2346, 17253,   262,   220,   220,   220,   220,\n",
       "           220,   220,  3098,    12,  9460,  2301,  2870,  1245,   286,   257,\n",
       "          4713,  1332, 10742,   286, 49599,    13,   685,  5188,    47,    60,\n",
       "         14719,   837, 23255,  2246,  4694,    62,    54, 10554,   837, 49599]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example, return_tensors='pt', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "entire-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(example):\n",
    "    res = tokenizer(example['triple_with_sentence'])\n",
    "    # res['label'] = example['LABEL']\n",
    "    res['label'] = 1 if example['LABEL']=='y' else 0\n",
    "    return res\n",
    "df['data'] = df.apply(processing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cardiovascular-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [21991, 750, 3662, 286, 14719, 11, 288, 361, 75, 403, 28456, 393, 49599, 2346, 17253, 262, 220, 220, 220, 220, 220, 220, 3098, 12, 9460, 2301, 2870, 1245, 286, 257, 4713, 1332, 10742, 286, 49599, 13, 685, 5188, 47, 60, 14719, 837, 23255, 2246, 4694, 62, 54, 10554, 837, 49599], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "german-ordinance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL', 'triple_with_sentence', 'data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-tumor",
   "metadata": {},
   "source": [
    "## split the data, training set 70%, validation set 15%, test set 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "centered-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "helpful-omaha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 450 450\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(val_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "approved-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index()\n",
    "val_data = val_data.reset_index()\n",
    "test_data = test_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unavailable-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# import evaluate\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "critical-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\t    predictions, labels = eval_pred\n",
    "\t    predictions = np.argmax(predictions, axis=1)\n",
    "\t    \n",
    "\t    # Calculate precision, recall, and F1 score\n",
    "\t    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "\t    \n",
    "\t    return {\n",
    "\t        'accuracy': accuracy_score(labels, predictions),\n",
    "\t        'precision': precision,\n",
    "\t        'recall': recall,\n",
    "\t        'f1': f1\n",
    "\t    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-champagne",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "binary-active",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'n', 1: 'y'}\n",
      "label2id: {'n': 0, 'y': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci5541/zhan8023/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/huggingface_hub/file_download.py:1006: UserWarning: Not enough free disk space to download the file. The expected file size is: 5312.67 MB. The target location /home/csci5541/zhan8023/.cache/huggingface/hub only has 520.09 MB free disk space.\n",
      "  warnings.warn(\n",
      "/home/csci5541/zhan8023/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/huggingface_hub/file_download.py:1006: UserWarning: Not enough free disk space to download the file. The expected file size is: 5312.67 MB. The target location /home/csci5541/zhan8023/.cache/huggingface/hub/models--EleutherAI--gpt-neo-1.3B/blobs only has 520.09 MB free disk space.\n",
      "  warnings.warn(\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForMaskedLM, GPTNeoForSequenceClassification\n",
    "\n",
    "labels = ['n', 'y']\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "\n",
    "print('id2label:', id2label)\n",
    "print('label2id:', label2id)\n",
    "\n",
    "model = GPTNeoForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Only train last classifier layer\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# # resize model embedding to match new tokenizer\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # fix model padding token id\n",
    "# model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unknown-parking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForSequenceClassification(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2048)\n",
       "    (wpe): Embedding(2048, 2048)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "assisted-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last one\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# for param in model.bert.pooler.dense.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# Unfreeze the last three layers\n",
    "# for param in model.transformer.ln_f.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-lighting",
   "metadata": {},
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baking-chocolate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='my_best_model',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sustained-butterfly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci5541/zhan8023/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/trainer.py:489\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    488\u001b[0m ):\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/trainer.py:730\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 730\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2555\u001b[0m         )\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data['data'],\n",
    "    eval_dataset=val_data['data'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-disney",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-birth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_jupyter_a40",
   "language": "python",
   "name": "pytorch_jupyter_a40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optional-brisbane",
   "metadata": {},
   "source": [
    "# Interview task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "attempted-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 20\n",
    "MODEL_NAME = \"microsoft/deberta-large-mnli\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-maker",
   "metadata": {},
   "source": [
    "## check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "arabic-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-controversy",
   "metadata": {},
   "source": [
    "## Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "alert-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "historic-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('substance_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "appreciated-finder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_START_INDEX</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1329</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1541</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>741</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_START_INDEX  OBJECT_END_INDEX  OBJECT_SCORE OBJECT_DIST  \\\n",
       "0                1329              1332          1000           2   \n",
       "1                 912               919           888           1   \n",
       "2                1541              1550          1000           1   \n",
       "3                 741               745           694           0   \n",
       "4                 480               491          1000           3   \n",
       "\n",
       "   OBJECT_MAXDIST     OBJECT_CUI OBJECT_NOVELTY  TYPE  \\\n",
       "0               2       C0004057              1    ab   \n",
       "1              15       C0242417              1    ab   \n",
       "2               1       C0003805              1    ab   \n",
       "3               4  C0169658|3716              1    ab   \n",
       "4               5       C0039815              1    ab   \n",
       "\n",
       "                                            SENTENCE  LABEL  \n",
       "0  Nor did administration of SA, diflunisal or AS...      n  \n",
       "1  A       comparative study of recombinant L-cha...      n  \n",
       "2  These findings suggest that some nicotinic alk...      y  \n",
       "3  With a       truncated chimaeric IL-5Rbeta-gp1...      y  \n",
       "4  Neutral       endopeptidase, a zinc-dependent ...      n  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "residential-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "spare-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>triple_with_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_END_INDEX  OBJECT_SCORE  OBJECT_DIST OBJECT_MAXDIST     OBJECT_CUI  \\\n",
       "0              1332          1000            2              2       C0004057   \n",
       "1               919           888            1             15       C0242417   \n",
       "2              1550          1000            1              1       C0003805   \n",
       "3               745           694            0              4  C0169658|3716   \n",
       "4               491          1000            3              5       C0039815   \n",
       "\n",
       "  OBJECT_NOVELTY TYPE                                           SENTENCE  \\\n",
       "0              1   ab  Nor did administration of SA, diflunisal or AS...   \n",
       "1              1   ab  A       comparative study of recombinant L-cha...   \n",
       "2              1   ab  These findings suggest that some nicotinic alk...   \n",
       "3              1   ab  With a       truncated chimaeric IL-5Rbeta-gp1...   \n",
       "4              1   ab  Neutral       endopeptidase, a zinc-dependent ...   \n",
       "\n",
       "   LABEL                               triple_with_sentence  \n",
       "0      n  Nor did administration of SA, diflunisal or AS...  \n",
       "1      n  A       comparative study of recombinant L-cha...  \n",
       "2      y  These findings suggest that some nicotinic alk...  \n",
       "3      y  With a       truncated chimaeric IL-5Rbeta-gp1...  \n",
       "4      n  Neutral       endopeptidase, a zinc-dependent ...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(example):\n",
    "    sentence = example['SENTENCE']\n",
    "    subject = example['SUBJECT_TEXT']\n",
    "    object = example['OBJECT_TEXT']\n",
    "    relation = example['PREDICATE']\n",
    "    # text = f\"{subject} [SEP] {relation} [SEP] {object} [SEP] {sentence}\"\n",
    "    text = f\"{sentence} [SEP] {subject} , {relation} , {object}\"\n",
    "    return text\n",
    "\n",
    "df['triple_with_sentence'] = df.apply(pre_processing,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-publication",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "democratic-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-biodiversity",
   "metadata": {},
   "source": [
    "#### test tokenizer for a triple with corresponding sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "assumed-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nor did administration of SA, diflunisal or ASA itself impair the       anti-aggregatory effect of a fresh test dose of ASA. [SEP] SA , INTERACTS_WITH , ASA'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['triple_with_sentence'].iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "intended-secret",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 29723,   222,   942,     9,  5531,     6,   385,  1594,   462,\n",
       "           879, 26860,    50, 36356,  1495, 29210,     5,  1437,  1437,  1437,\n",
       "          1437,  1437,  1437,  1475,    12,  7165,  4950,  5257,  1683,     9,\n",
       "            10,  2310,  1296, 12234,     9, 36356,     4,  1437,     2,  5531,\n",
       "          2156, 20281,  2562,  2685,  1215,   771, 27698,  2156, 36356,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example, return_tensors='pt', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "about-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(example):\n",
    "    res = tokenizer(example['triple_with_sentence'])\n",
    "    # res['label'] = example['LABEL']\n",
    "    res['label'] = 1 if example['LABEL']=='y' else 0\n",
    "    return res\n",
    "df['data'] = df.apply(processing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "working-concrete",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 29723, 222, 942, 9, 5531, 6, 385, 1594, 462, 879, 26860, 50, 36356, 1495, 29210, 5, 1437, 1437, 1437, 1437, 1437, 1437, 1475, 12, 7165, 4950, 5257, 1683, 9, 10, 2310, 1296, 12234, 9, 36356, 4, 1437, 2, 5531, 2156, 20281, 2562, 2685, 1215, 771, 27698, 2156, 36356, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "spare-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL', 'triple_with_sentence', 'data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-shooting",
   "metadata": {},
   "source": [
    "## split the data, training set 70%, validation set 15%, test set 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "biological-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=RANDOM_STATE)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "pending-wheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 450 450\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(val_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "informed-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index()\n",
    "val_data = val_data.reset_index()\n",
    "test_data = test_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "funny-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# import evaluate\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "organic-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\t    predictions, labels = eval_pred\n",
    "\t    predictions = np.argmax(predictions, axis=1)\n",
    "\t    \n",
    "\t    # Calculate precision, recall, and F1 score\n",
    "\t    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "\t    \n",
    "\t    return {\n",
    "\t        'accuracy': accuracy_score(labels, predictions),\n",
    "\t        'precision': precision,\n",
    "\t        'recall': recall,\n",
    "\t        'f1': f1\n",
    "\t    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-equation",
   "metadata": {},
   "source": [
    "## BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "handed-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'n', 1: 'y'}\n",
      "label2id: {'n': 0, 'y': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([2, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "labels = ['n', 'y']\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "\n",
    "print('id2label:', id2label)\n",
    "print('label2id:', label2id)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Only train last classifier layer\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# resize model embedding to match new tokenizer\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # fix model padding token id\n",
    "# model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "instructional-harvey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 1024)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "atomic-wyoming",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last one\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# for param in model.bert.pooler.dense.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # Unfreeze the last three layers\n",
    "# for param in model.transformer.ln_f.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-pricing",
   "metadata": {},
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "subsequent-mainstream",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='my_best_model',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "atlantic-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci5541/zhan8023/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [660/660 05:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.729927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.598130</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.670139</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.731061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.593626</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.657807</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.731978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.593252</td>\n",
       "      <td>0.682222</td>\n",
       "      <td>0.656958</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>0.739526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.606164</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.592966</td>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.660317</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.749550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.583731</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.733945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>0.579852</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.661074</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.732342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>0.585483</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.746377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>0.584271</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.743169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory my_best_model/checkpoint-66 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-132 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-198 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-264 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-330 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-396 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-462 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-528 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-594 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory my_best_model/checkpoint-660 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=660, training_loss=0.6058517456054687, metrics={'train_runtime': 334.8742, 'train_samples_per_second': 62.71, 'train_steps_per_second': 1.971, 'total_flos': 7526117193318096.0, 'train_loss': 0.6058517456054687, 'epoch': 10.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data['data'],\n",
    "    eval_dataset=val_data['data'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "pressing-stylus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5725005865097046,\n",
       " 'eval_accuracy': 0.6976190476190476,\n",
       " 'eval_precision': 0.6802030456852792,\n",
       " 'eval_recall': 0.8286219081272085,\n",
       " 'eval_f1': 0.7471127041019514,\n",
       " 'eval_runtime': 22.8023,\n",
       " 'eval_samples_per_second': 92.096,\n",
       " 'eval_steps_per_second': 2.894,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fundamental-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5798524022102356,\n",
       " 'eval_accuracy': 0.68,\n",
       " 'eval_precision': 0.6610738255033557,\n",
       " 'eval_recall': 0.8208333333333333,\n",
       " 'eval_f1': 0.7323420074349443,\n",
       " 'eval_runtime': 4.3727,\n",
       " 'eval_samples_per_second': 102.911,\n",
       " 'eval_steps_per_second': 3.43,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(val_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sunset-sheffield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5823975801467896,\n",
       " 'eval_accuracy': 0.6755555555555556,\n",
       " 'eval_precision': 0.6505190311418685,\n",
       " 'eval_recall': 0.8068669527896996,\n",
       " 'eval_f1': 0.7203065134099617,\n",
       " 'eval_runtime': 4.1466,\n",
       " 'eval_samples_per_second': 108.522,\n",
       " 'eval_steps_per_second': 3.617,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-reader",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

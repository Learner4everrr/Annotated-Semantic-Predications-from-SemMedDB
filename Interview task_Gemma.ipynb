{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vietnamese-burlington",
   "metadata": {},
   "source": [
    "# Interview task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "hydraulic-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Rocketknight1/falcon-rw-1b\"\n",
    "RANDOM_STATE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-hindu",
   "metadata": {},
   "source": [
    "## check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "gorgeous-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-seeking",
   "metadata": {},
   "source": [
    "## Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "arctic-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "blessed-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('substance_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "eleven-secretary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_START_INDEX</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1329</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1541</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>741</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_START_INDEX  OBJECT_END_INDEX  OBJECT_SCORE OBJECT_DIST  \\\n",
       "0                1329              1332          1000           2   \n",
       "1                 912               919           888           1   \n",
       "2                1541              1550          1000           1   \n",
       "3                 741               745           694           0   \n",
       "4                 480               491          1000           3   \n",
       "\n",
       "   OBJECT_MAXDIST     OBJECT_CUI OBJECT_NOVELTY  TYPE  \\\n",
       "0               2       C0004057              1    ab   \n",
       "1              15       C0242417              1    ab   \n",
       "2               1       C0003805              1    ab   \n",
       "3               4  C0169658|3716              1    ab   \n",
       "4               5       C0039815              1    ab   \n",
       "\n",
       "                                            SENTENCE  LABEL  \n",
       "0  Nor did administration of SA, diflunisal or AS...      n  \n",
       "1  A       comparative study of recombinant L-cha...      n  \n",
       "2  These findings suggest that some nicotinic alk...      y  \n",
       "3  With a       truncated chimaeric IL-5Rbeta-gp1...      y  \n",
       "4  Neutral       endopeptidase, a zinc-dependent ...      n  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "spare-answer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "defined-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>INDICATOR_TYPE</th>\n",
       "      <th>PREDICATE_START_INDEX</th>\n",
       "      <th>PREDICATE_END_INDEX</th>\n",
       "      <th>SUBJECT_TEXT</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_START_INDEX</th>\n",
       "      <th>SUBJECT_END_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>OBJECT_END_INDEX</th>\n",
       "      <th>OBJECT_SCORE</th>\n",
       "      <th>OBJECT_DIST</th>\n",
       "      <th>OBJECT_MAXDIST</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>triple_with_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3100</td>\n",
       "      <td>6499897</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>1298</td>\n",
       "      <td>1304</td>\n",
       "      <td>SA</td>\n",
       "      <td>orch</td>\n",
       "      <td>1235</td>\n",
       "      <td>1237</td>\n",
       "      <td>...</td>\n",
       "      <td>1332</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C0004057</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "      <td>n</td>\n",
       "      <td>Nor did administration of SA, diflunisal or AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P3101</td>\n",
       "      <td>8369307</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>890</td>\n",
       "      <td>899</td>\n",
       "      <td>rHF</td>\n",
       "      <td>aapp</td>\n",
       "      <td>785</td>\n",
       "      <td>788</td>\n",
       "      <td>...</td>\n",
       "      <td>919</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>C0242417</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "      <td>n</td>\n",
       "      <td>A       comparative study of recombinant L-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3102</td>\n",
       "      <td>3711333</td>\n",
       "      <td>INHIBITS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1527</td>\n",
       "      <td>1534</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>orch</td>\n",
       "      <td>1508</td>\n",
       "      <td>1517</td>\n",
       "      <td>...</td>\n",
       "      <td>1550</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003805</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "      <td>y</td>\n",
       "      <td>These findings suggest that some nicotinic alk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3103</td>\n",
       "      <td>11742534</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>NOM</td>\n",
       "      <td>746</td>\n",
       "      <td>753</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>aapp</td>\n",
       "      <td>703</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>745</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>C0169658|3716</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "      <td>y</td>\n",
       "      <td>With a       truncated chimaeric IL-5Rbeta-gp1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P3104</td>\n",
       "      <td>244385</td>\n",
       "      <td>STIMULATES</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>410</td>\n",
       "      <td>419</td>\n",
       "      <td>Neutral       endopeptidase</td>\n",
       "      <td>aapp</td>\n",
       "      <td>374</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>C0039815</td>\n",
       "      <td>1</td>\n",
       "      <td>ab</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "      <td>n</td>\n",
       "      <td>Neutral       endopeptidase, a zinc-dependent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID      PMID       PREDICATE INDICATOR_TYPE  \\\n",
       "0          P3100   6499897  INTERACTS_WITH            NOM   \n",
       "1          P3101   8369307        INHIBITS           VERB   \n",
       "2          P3102   3711333        INHIBITS           VERB   \n",
       "3          P3103  11742534  INTERACTS_WITH            NOM   \n",
       "4          P3104    244385      STIMULATES            ADJ   \n",
       "\n",
       "   PREDICATE_START_INDEX  PREDICATE_END_INDEX                 SUBJECT_TEXT  \\\n",
       "0                   1298                 1304                           SA   \n",
       "1                    890                  899                          rHF   \n",
       "2                   1527                 1534                    alkaloids   \n",
       "3                    746                  753                  amino acids   \n",
       "4                    410                  419  Neutral       endopeptidase   \n",
       "\n",
       "  SUBJECT_SEMTYPE  SUBJECT_START_INDEX  SUBJECT_END_INDEX  ...  \\\n",
       "0            orch                 1235               1237  ...   \n",
       "1            aapp                  785                788  ...   \n",
       "2            orch                 1508               1517  ...   \n",
       "3            aapp                  703                714  ...   \n",
       "4            aapp                  374                401  ...   \n",
       "\n",
       "   OBJECT_END_INDEX  OBJECT_SCORE  OBJECT_DIST OBJECT_MAXDIST     OBJECT_CUI  \\\n",
       "0              1332          1000            2              2       C0004057   \n",
       "1               919           888            1             15       C0242417   \n",
       "2              1550          1000            1              1       C0003805   \n",
       "3               745           694            0              4  C0169658|3716   \n",
       "4               491          1000            3              5       C0039815   \n",
       "\n",
       "  OBJECT_NOVELTY TYPE                                           SENTENCE  \\\n",
       "0              1   ab  Nor did administration of SA, diflunisal or AS...   \n",
       "1              1   ab  A       comparative study of recombinant L-cha...   \n",
       "2              1   ab  These findings suggest that some nicotinic alk...   \n",
       "3              1   ab  With a       truncated chimaeric IL-5Rbeta-gp1...   \n",
       "4              1   ab  Neutral       endopeptidase, a zinc-dependent ...   \n",
       "\n",
       "   LABEL                               triple_with_sentence  \n",
       "0      n  Nor did administration of SA, diflunisal or AS...  \n",
       "1      n  A       comparative study of recombinant L-cha...  \n",
       "2      y  These findings suggest that some nicotinic alk...  \n",
       "3      y  With a       truncated chimaeric IL-5Rbeta-gp1...  \n",
       "4      n  Neutral       endopeptidase, a zinc-dependent ...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(example):\n",
    "    sentence = example['SENTENCE']\n",
    "    subject = example['SUBJECT_TEXT']\n",
    "    object = example['OBJECT_TEXT']\n",
    "    relation = example['PREDICATE']\n",
    "    # text = f\"{subject} [SEP] {relation} [SEP] {object} [SEP] {sentence}\"\n",
    "    text = f\"{sentence} [SEP] {subject} , {relation} , {object}\"\n",
    "    return text\n",
    "\n",
    "df['triple_with_sentence'] = df.apply(pre_processing,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-preservation",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "after-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# # default to left padding\n",
    "# tokenizer.padding_side = \"left\"\n",
    "# # Define PAD Token = EOS Token = 50256\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-dependence",
   "metadata": {},
   "source": [
    "#### test tokenizer for a triple with corresponding sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "quarterly-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nor did administration of SA, diflunisal or ASA itself impair the       anti-aggregatory effect of a fresh test dose of ASA. [SEP] SA , INTERACTS_WITH , ASA'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['triple_with_sentence'].iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "written-recycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[21991,   750,  3662,   286, 14719,    11,   288,   361,    75,   403,\n",
       "         28456,   393, 49599,  2346, 17253,   262,   220,   220,   220,   220,\n",
       "           220,   220,  3098,    12,  9460,  2301,  2870,  1245,   286,   257,\n",
       "          4713,  1332, 10742,   286, 49599,    13,   685,  5188,    47,    60,\n",
       "         14719,   837, 23255,  2246,  4694,    62,    54, 10554,   837, 49599]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example, return_tensors='pt', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "latter-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(example):\n",
    "    res = tokenizer(example['triple_with_sentence'])\n",
    "    # res['label'] = example['LABEL']\n",
    "    res['label'] = 1 if example['LABEL']=='y' else 0\n",
    "    return res\n",
    "df['data'] = df.apply(processing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "speaking-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [21991, 750, 3662, 286, 14719, 11, 288, 361, 75, 403, 28456, 393, 49599, 2346, 17253, 262, 220, 220, 220, 220, 220, 220, 3098, 12, 9460, 2301, 2870, 1245, 286, 257, 4713, 1332, 10742, 286, 49599, 13, 685, 5188, 47, 60, 14719, 837, 23255, 2246, 4694, 62, 54, 10554, 837, 49599], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 0}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "regular-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PREDICATION_ID', 'PMID', 'PREDICATE', 'INDICATOR_TYPE',\n",
       "       'PREDICATE_START_INDEX', 'PREDICATE_END_INDEX', 'SUBJECT_TEXT',\n",
       "       'SUBJECT_SEMTYPE', 'SUBJECT_START_INDEX', 'SUBJECT_END_INDEX',\n",
       "       'SUBJECT_SCORE', 'SUBJECT_DIST', 'SUBJECT_MAXDIST', 'SUBJECT_CUI',\n",
       "       'SUBJECT_NOVELTY', 'OBJECT_TEXT', 'OBJECT_SEMTYPE',\n",
       "       'OBJECT_START_INDEX', 'OBJECT_END_INDEX', 'OBJECT_SCORE', 'OBJECT_DIST',\n",
       "       'OBJECT_MAXDIST', 'OBJECT_CUI', 'OBJECT_NOVELTY', 'TYPE', 'SENTENCE',\n",
       "       'LABEL', 'triple_with_sentence', 'data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-coalition",
   "metadata": {},
   "source": [
    "## split the data, training set 70%, validation set 15%, test set 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "latin-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "relevant-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 450 450\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(val_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "trying-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index()\n",
    "val_data = val_data.reset_index()\n",
    "test_data = test_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "equal-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# import evaluate\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dutch-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\t    predictions, labels = eval_pred\n",
    "\t    predictions = np.argmax(predictions, axis=1)\n",
    "\t    \n",
    "\t    # Calculate precision, recall, and F1 score\n",
    "\t    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "\t    \n",
    "\t    return {\n",
    "\t        'accuracy': accuracy_score(labels, predictions),\n",
    "\t        'precision': precision,\n",
    "\t        'recall': recall,\n",
    "\t        'f1': f1\n",
    "\t    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-banner",
   "metadata": {},
   "source": [
    "## BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "spread-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label: {0: 'n', 1: 'y'}\n",
      "label2id: {'n': 0, 'y': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FalconForSequenceClassification were not initialized from the model checkpoint at Rocketknight1/falcon-rw-1b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import FalconForSequenceClassification\n",
    "\n",
    "labels = ['n', 'y']\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "\n",
    "print('id2label:', id2label)\n",
    "print('label2id:', label2id)\n",
    "\n",
    "model = FalconForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "# num_labels=len(labels), id2label=id2label, label2id=label2id\n",
    "\n",
    "# Only train last classifier layer\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# # resize model embedding to match new tokenizer\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # fix model padding token id\n",
    "# model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "material-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FalconForSequenceClassification(\n",
       "  (transformer): FalconModel(\n",
       "    (word_embeddings): Embedding(50304, 2048)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x FalconDecoderLayer(\n",
       "        (self_attention): FalconAttention(\n",
       "          (query_key_value): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
       "          (dense): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): FalconMLP(\n",
       "          (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "posted-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze all layers except the last one\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # for param in model.bert.pooler.dense.parameters():\n",
    "# #     param.requires_grad = True\n",
    "\n",
    "# # # Unfreeze the last three layers\n",
    "# # for param in model.transformer.ln_f.parameters():\n",
    "# #     param.requires_grad = True\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-wheel",
   "metadata": {},
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "occupational-recycling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='my_best_model',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "prostate-teach",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/trainer.py:362\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m enable_full_determinism(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfull_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/trainer_utils.py:95\u001b[0m, in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     93\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:17\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/cuda/random.py:126\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    123\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    124\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 126\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/cuda/__init__.py:232\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/torch/cuda/random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    123\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 124\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data['data'],\n",
    "    eval_dataset=val_data['data'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "opposed-christmas",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AcceleratorState' object has no attribute 'distributed_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[242], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/trainer.py:3222\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m   3220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 3222\u001b[0m eval_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_eval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   3224\u001b[0m     eval_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(eval_dataloader)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/transformers/trainer.py:910\u001b[0m, in \u001b[0;36mTrainer.get_eval_dataloader\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    907\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_drop_last\n\u001b[1;32m    908\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefetch_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_prefetch_factor\n\u001b[0;32m--> 910\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataloader_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/accelerate/accelerator.py:1219\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1209\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m     ):\n\u001b[1;32m   1214\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1217\u001b[0m         )\n\u001b[0;32m-> 1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   1220\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_jupyter_a40/lib/python3.12/site-packages/accelerate/accelerator.py:509\u001b[0m, in \u001b[0;36mAccelerator.distributed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistributed_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AcceleratorState' object has no attribute 'distributed_type'"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(test_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-science",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, FalconForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rocketknight1/falcon-rw-1b\")\n",
    "model = FalconForSequenceClassification.from_pretrained(\"Rocketknight1/falcon-rw-1b\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "print(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-swaziland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_jupyter_a40",
   "language": "python",
   "name": "pytorch_jupyter_a40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
